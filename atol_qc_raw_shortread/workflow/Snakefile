#!/usr/bin/env python3

import tempfile


def get_rg_line(wildcards):
    rg_args = ""
    if dataset_id:
        rg_args = " ".join(
            [rg_args, f"-r ID:{dataset_id} -r PU:{dataset_id} -r SM:{dataset_id}"]
        )
    if hic_kit:
        rg_args = " ".join([rg_args, f"-r CN:{hic_kit}"])

    return rg_args.lstrip().rstrip()


# The default prefix is 'set -euo pipefail; '. We are adding a sleep to ALL
# shell commands to bypass a clock skew problem on HPC filesystems. See
# https://github.com/snakemake/snakemake/issues/3261#issuecomment-2663727316
# and
# https://github.com/snakemake/snakemake/issues/3254#issuecomment-2598641487.
shell.prefix("set -euo pipefail; sleep 5; ")

globals().update(config)
workingdir = tempfile.mkdtemp()
logger.warning(f"Using {workingdir} for intermediate files")

stats_directory = stats.parent
logger.warning(f"Stats files will be saved to stats_directory {stats_directory}")

if not logs_directory:
    logger.warning(f"Not keeping logs")
    logs_directory = workingdir
else:
    logger.warning(f"Saving logs to {logs_directory}")


include: "rules/stats.smk"


rule samtools_import:
    input:
        pipe=Path(workingdir, "trim", "reads.fastq")
    output:
        cram=cram_out if cram_out else [],
        index=Path(cram_out.as_posix() + ".crai") if cram_out else [],
        flagstat=cram_out.with_suffix(".flagstat") if cram_out else [],
    params:
        rg_line=get_rg_line,
    log:
        Path(logs_directory, "samtools_import.log"),
    shell:
        "samtools import "
        "-@{threads} "
        "-s {input.pipe} "
        "{params.rg_line} "
        "-o {output.cram} "
        "2> {log} "
        "&& "
        "samtools index "
        "{output.cram} "
        "2>> {log} "
        "&& "
        "samtools flagstat "
        "{output.cram} "
        "> {output.flagstat} "
        "2>> {log} "



rule reformat:
    input:
        pipe=Path(workingdir, "trim", "reads.fastq") if r1_out else [],
    output:
        r1=r1_out if r1_out else [],
        r2=r2_out if r1_out else [],
    log:
        Path(logs_directory, "reformat.log"),
    resources:
        mem=lambda wildcards, attempt: f"{4* attempt}GiB",
    shell:
        "reformat.sh "
        "-Xmx{resources.mem_mb}m "
        "threads={threads} "
        "in={input.pipe} "
        "int=t "
        "out={output.r1} "
        "out2={output.r2} "
        "2> {log} "

        

rule trim:
    input:
        pipe=Path(workingdir, "repair", "reads.fastq"),
        adaptors=Path(workingdir, "adaptors.fasta"),
    output:
        gchist=Path(logs_directory, "gchist.txt"),
        stats=Path(logs_directory, "trim_stats.txt"),
        unpaired=Path(workingdir, "unpaired.fq.gz"),
        pipe=pipe(Path(workingdir, "trim", "reads.fastq")),
    params:
        forcetrimmod=5,
        qtrim=lambda wildcards: f"qtrim=r trimq={trimq} " if qtrim else "",
    log:
        trim=Path(logs_directory, "trim.log"),
        rename=Path(logs_directory, "rename.log"),
    threads: workflow.cores - 3  # save 2 cores for repair and one for reformat
    resources:
        mem=lambda wildcards, attempt: f"{4* attempt}GiB",
    shell:
        "bbduk.sh "
        "-Xmx{resources.mem_mb}m "
        "threads={threads} "
        "in={input.pipe} "
        "int=t "
        "out=stdout.fastq "
        "outs={output.unpaired} "
        "ref={input.adaptors} "
        "ktrim=r k=23 mink=11 hdist=1 tpe tbo "
        "forcetrimmod={params.forcetrimmod} "
        "{params.qtrim}"
        "gchist={output.gchist} "
        "stats={output.stats} "
        "2> {log.trim} " 
        "| "
        "reformat.sh "
        "in=stdin.fastq "
        "int=t "
        "out=stdout.fastq "
        "trimreaddescription=t "    # required for samtools import
        "addslash=t "               # required for samtools import
        "spaceslash=f "             # required for samtools import
        ">> {output.pipe} "
        "2> {log.rename} "

# double check pairing
rule repair:
    input:
        r1=r1,
        r2=r2,
    output:
        pipe(Path(workingdir, "repair", "reads.fastq")),
    log:
        Path(logs_directory, "repair.log"),
    threads: 2
    resources:
        mem=lambda wildcards, attempt: f"{4* attempt}GiB",
    shell:
        "repair.sh "
        "-Xmx{resources.mem_mb}m "
        "-Xms100m "
        "in={input.r1} "
        "in2={input.r2} "
        "out=stdout.fastq "
        "outs=/dev/null "
        "repair=t "
        "tossbrokenreads=t "
        "tossjunk=t "
        ">> {output} "
        "2> {log}"


rule combine_adaptors:
    input:
        adaptors,
    output:
        adaptors=Path(workingdir, "adaptors.fasta"),
        duplicates=Path(logs_directory, "duplicated_adaptors.fasta"),
    log:
        Path(logs_directory, "combine_adaptors.log"),
    threads: 1
    resources:
        mem="4GiB",
    shell:
        "cat {input} | "
        "dedupe.sh "
        "-Xmx{resources.mem_mb}m "
        "in=stdin.fasta "
        "out={output.adaptors} "
        "outd={output.duplicates} "
        "absorbcontainment=f "
        "absorbrc=f "
        "ascending=t "
        "exact=t "
        "maxedits=0 "
        "maxsubs=0 "
        "sort=name "
        "touppercase=t "
        "uniquenames=t "
        "2> {log} "


if cram_out:
    reads_out = rules.samtools_import.output

if r1_out:
    reads_out = rules.reformat.output


rule target:
    default_target: True
    input:
        rules.output_stats.output,
        reads_out,
