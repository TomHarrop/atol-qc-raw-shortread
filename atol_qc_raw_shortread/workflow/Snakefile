#!/usr/bin/env python3

import tempfile


globals().update(config)
workingdir = tempfile.mkdtemp()
logger.warning(f"Using {workingdir} for intermediate files")

stats_directory = stats.parent
logger.warning(f"Stats files will be saved to stats_directory {stats_directory}")

if not logs_directory:
    logger.warning(f"Not keeping logs")
    logs_directory = workingdir
else:
    logger.warning(f"Saving logs to {logs_directory}")


include: "rules/stats.smk"


rule trim:
    input:
        pipe=Path(workingdir, "repair", "reads.fastq"),
        adaptors=Path(workingdir, "adaptors.fasta"),
    output:
        gchist=Path(logs_directory, "gchist.txt"),
        r1=r1_out,
        r2=r2_out,
        stats=Path(logs_directory, "trim_stats.txt"),
        unpaired=Path(workingdir, "unpaired.fq.gz"),
    params:
        forcetrimmod=5,
        qtrim=lambda wildcards: f"qtrim=r trimq={trimq}" if qtrim else "",
        threads=lambda wildcards, threads: int(threads // 3), # split cores between bbduk and pigz
    log:
        Path(logs_directory, "trim.log"),
    threads: workflow.cores - 2  # save 2 cores for repair
    resources:
        mem=lambda wildcards, attempt: f"{4* attempt}GiB",
    shell:
        "bbduk.sh "
        "-Xmx{resources.mem_mb}m "
        "threads={params.threads} "
        "in={input.pipe} "
        "int=t "
        "out={output.r1} "
        "out2={output.r2} "
        "outs={output.unpaired} "
        "ref={input.adaptors} "
        "ktrim=r k=23 mink=11 hdist=1 tpe tbo "
        "forcetrimmod={params.forcetrimmod} "
        "{params.qtrim} "
        "gchist={output.gchist} "
        "stats={output.stats} "
        "zl=9 "
        "2> {log} "


# double check pairing
rule repair:
    input:
        r1=r1,
        r2=r2,
    output:
        pipe(Path(workingdir, "repair", "reads.fastq")),
    log:
        Path(logs_directory, "repair.log"),
    threads: 2
    resources:
        mem=lambda wildcards, attempt: f"{4* attempt}GiB",
    shell:
        "repair.sh "
        "-Xmx{resources.mem_mb}m "
        "-Xms100m "
        "in={input.r1} "
        "in2={input.r2} "
        "out=stdout.fastq "
        "outs=/dev/null "
        "repair=t "
        "tossbrokenreads=t "
        "tossjunk=t "
        ">> {output} "
        "2> {log}"


rule combine_adaptors:
    input:
        adaptors,
    output:
        adaptors=Path(workingdir, "adaptors.fasta"),
        duplicates=Path(logs_directory, "duplicated_adaptors.fasta"),
    log:
        Path(logs_directory, "combine_adaptors.log"),
    threads: 1
    resources:
        mem="4GiB",
    shell:
        "cat {input} | "
        "dedupe.sh "
        "-Xmx{resources.mem_mb}m "
        "in=stdin.fasta "
        "out={output.adaptors} "
        "outd={output.duplicates} "
        "absorbcontainment=f "
        "absorbrc=f "
        "ascending=t "
        "exact=t "
        "maxedits=0 "
        "maxsubs=0 "
        "sort=name "
        "touppercase=t "
        "uniquenames=t "
        "2> {log} "


rule target:
    default_target: True
    input:
        rules.output_stats.output,
        rules.trim.output,
